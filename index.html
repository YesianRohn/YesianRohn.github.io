<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Yesian Rohn</title>

  <meta name="author" content="Yesian Rohn">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" href="favicon.ico">

  <style>
    #visitors {
      display: inline-block;
      margin-right: 10px;
    }
  </style>

</head>



<body>
  <div id="visitors">
    Visitors:
  </div>
  <img src="https://profile-counter.glitch.me/yesianrohn/count.svg" alt="Visitor Count">

  <table
    style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p style="text-align:center">
                    <name>Yesian Rohn | Xingsong Ye</name>
                  </p>
                  <p>
                    I am a Master's student in Computer Science at <a href="https://www.fudan.edu.cn">Fudan
                      University</a>, under the supervision of <a
                      href="https://zhinchenfd.github.io">Prof. Zhineng Chen</a> in the <a
                      href="https://fvl.fudan.edu.cn">FVL Group</a>. 
                    Before that, nothing had happened.
                  </p>
                  <p>I am currently focused on projects involving OCR, MultiModal, AIGC (C means
                    Comedy). Please connect and collaborate with me to explore the potential of these fields and leverage them to make a positive impact on exciting computer science projects!
                  </p>
                  <p style="text-align:left">
                    <a href="mailto:xsye20@fudan.edu.cn">Email</a> &nbsp/&nbsp
                    <a href="CV.pdf">CV</a> &nbsp/&nbsp
                    <a href="https://scholar.google.com/citations?user=xMl7sSIAAAAJ">Google Scholar</a> &nbsp/&nbsp
                    <a href="https://openreview.net/profile?id=~Xingsong_Ye1">OpenReview</a> &nbsp/&nbsp
                    <a href="https://github.com/YesianRohn">Github</a> &nbsp/&nbsp
                    <a href="https://space.bilibili.com/225946390">Bilibili</a> &nbsp/&nbsp
                    <a href="https://www.zhihu.com/people/yesianrohn">Zhihu</a>
                  </p>
                </td>
                <td style="padding:2.5%;width:40%;max-width:40%">
                  <a href="profile.png"><img style="width:100%;max-width:100%" alt="profile photo" src="profile.png"
                      class="hoverZoomLink"></a>
                </td>
              </tr>
            </tbody>
          </table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            
            <heading style="padding:20px;width:100%">Publications</heading>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/TextSSR.svg" alt="clean-usnob" width="160" height="100">
              </td>
              <td width="75%" valign="middle">
                <a>
                  <span class="papertitle">TextSSR: Diffusion-based Data Synthesis for Scene Text Recognition</span>
                </a>
                <br>
                <strong>Xingsong Ye</strong>, Yongkun Du, Yunbo Tao, Zhineng Chen
                <br>
                <em>arXiv</em>, 2024
                <br>
                <a href="https://textssr.github.io">project page</a>
                /
                <a href="https://arxiv.org/abs/2412.01137">arXiv</a>
                /
                <a href="https://github.com/YesianRohn/TextSSR">code</a>
                /
                <a href="https://www.modelscope.cn/studios/Yesianrohn/TextSSR">demo</a>
                <p></p>
                <p>We introduce TextSSR: a novel framework for Synthesizing Scene Text Recognition data via a diffusion-based universal text region synthesis model. It ensures accuracy by focusing on generating text within a specified image region and leveraging rich glyph and position information to create the less complex text region compared to the entire image. Furthermore, we utilize neighboring text within the region as a prompt to capture real-world font styles and layout patterns, guiding the generated text to resemble actual scenes. Finally, due to its prompt-free nature and capability for character-level synthesis, TextSSR enjoys a wonderful scalability.</p>
              </td>
            </tr>         

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/SIUO.png" alt="clean-usnob" width="160" height="160">
              </td>
              <td width="75%" valign="middle">
                <a>
                  <span class="papertitle">Cross-Modality Safety Alignment</span>
                </a>
                <br>
                Siyin Wang, <strong>Xingsong Ye</strong>, Qinyuan Cheng, Junwen Duan, Shimin Li, Jinlan Fu, Xipeng Qiu, Xuanjing Huang
                <br>
                <em>arXiv</em>, 2024
                <br>
                <a href="https://sinwang20.github.io/SIUO/">project page</a>
                /
                <a href="https://arxiv.org/abs/2406.15279">arXiv</a>
                /
                <a href="https://github.com/sinwang20/SIUO">code</a>
                /
                <a href="https://huggingface.co/datasets/sinwang/SIUO">dataset</a>
                <p></p>
                <p>We introduce a novel safety alignment challenge called Safe Inputs but Unsafe Output (SIUO) to evaluate cross-modality safety alignment. Specifically, it considers cases where single modalities are safe independently but could potentially lead to unsafe or unethical outputs when combined.</p>
              </td>
            </tr>         

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/cl2s.png" alt="clean-usnob" width="160" height="160">
              </td>
              <td width="75%" valign="middle">
                <a>
                  <span class="papertitle">Rethinking the Elementary function fusion for Single-Image Dehazing</span>
                </a>
                <br>
                <strong>Yesian Rohn</strong>
                <br>
                <em>Course Project of DIP</em>, 2024
                /
                <em>arXiv</em>, 2024
                <br>
                <a href="https://arxiv.org/abs/2405.15817">arXiv</a>
                /
                <a href="https://github.com/YesianRohn/CL2S">code</a>
                <p></p>
                <p>We introduce CL2S, an innovative image dehazing network that overcomes limitations of DM2F (baseline) by trying sine functions, as validated through systematic ablation experiments.</p>
              </td>
            </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/duanzai.png" alt="clean-usnob" width="160" height="160">
            </td>
            <td width="75%" valign="middle">
              <a>
                <span class="papertitle">DuanzAI: Slang-Enhanced LLM with Prompt for Humor Understanding</span>
              </a>
              <br>
              <strong>Yesian Rohn</strong>
              <br>
              <em>Xiyuan Project of FDUROP</em>, 2023 - 2024
              /
              <em>arXiv</em>, 2024
              <br>
              <a href="https://chatdai.github.io/">project page</a>
              /
              <a href="https://arxiv.org/abs/2405.15818">arXiv</a>
              /
              <a href="https://github.com/YesianRohn/DuanzAI">code</a>
              <p></p>
              <p>We enhance LLMs' understanding of Chinese slang using curated datasets and advanced techniques, introducing DuanzAI and its application in the ChatDAI chatbot.</p>
            </td>
          </tr>

        </tbody></table>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading>Honor</heading>
                  <ul>
                    <li> Fudan Excellent League Member, Spring 2024.</li>
                    <li> Third-class in Fudan Guanghua Social and Academic Practice Competition, Winter 2023.</li>
                    <li> Fudan Outstanding Student, Autumn 2023.</li>
                    <li> Alibaba Cloud Annual Geek of Greencode, Winter 2022. </li>
                  </ul>
                </td>
              </tr>
            </tbody>
          </table>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading>Awards</heading>
                  <ul>
                    <li> Jinrirencai Scholarship, Spring 2024.</li>
                    <li> First-class Scholarship of Fudan University (Graduate Scholarship), Spring 2024.</li>
                    <li> Duckbill Scholarship (Endowed Scholarship of Fudan University), Autumn 2023.</li>
                    <li> Pujiang Innovation Forum Volunteer Nickname Bid-Winning Award, Summer 2023.</li>
                    <li> Third-class Scholarship of Fudan University, Autumn 2022.</li>
                  </ul>
                </td>
              </tr>
            </tbody>
          </table>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading>Service</heading>
                  <p>
                    <b>Teaching / TA</b>
                  </p>
                  <ul>
                    <li><a href="https://cs.fudan.edu.cn/17/c5/c35220a268229/page.htm">Set Theory and Graph Theory</a> (2024 Autumn)</li>
                    <li><a href="https://aifep-fdu.github.io/">Practical Exploration of Frontiers in Artificial Intelligence(G)</a> (2024 Autumn)</li>
                    <li><a href="https://ai-fdu.github.io/">Artificial Intelligence A</a> (2024 Spring)</li>
                  </ul>
                  <p>
                    <b>Referee / Reviewer</b>
                  </p>
                  <ul>
                    <li><a href="https://link.springer.com/journal/530">Multimedia Systems</a> (2024)</li>
                    <li><a href="https://15.sanguosha.com">TWTK</a> (2023)</li>
                  </ul>
                </td>
              </tr>
            </tbody>
          </table>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:0px">
                  <p font-size:small;="">
                    <br>
                    <br>
                  </p>
                  <div style="float:left;">
                    Updated at July 2024.
                  </div>
                  <div style="float:right;">
                    Thanks to Jon Barron's <a href="https://jonbarron.info">template.</a>
                  </div>
                  <br>
                  <br>
                  <p></p>
                </td>
              </tr>
            </tbody>
          </table>


        </td>
      </tr>
  </table>
</body>

</html>
